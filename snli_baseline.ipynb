{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "from sklearn import linear_model\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import sys\n",
    "import unicodedata\n",
    "import string\n",
    "import operator\n",
    "import math\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from scipy import sparse\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "stdout = sys.stdout\n",
    "reload(sys)  \n",
    "sys.setdefaultencoding('utf8')\n",
    "sys.stdout = stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import os\n",
    "\n",
    "class Preprocessor:\n",
    "    def __init__(self, dataDir = './'):\n",
    "        self.data = []\n",
    "        self.dataDir = dataDir \n",
    "\n",
    "    def isSampleValid(self, sample):\n",
    "        return sample['gold_label'] != '-'\n",
    "    \n",
    "    def getDataFromJSONL(self, filename):\n",
    "        numInvalid = 0\n",
    "        with open(filename) as fp:\n",
    "            reader = jsonlines.Reader(fp)\n",
    "            for obj in reader.iter(type=dict, skip_invalid=True):\n",
    "                if self.isSampleValid(obj):\n",
    "                    sample = {}\n",
    "                    sample['gold_label'] = obj['gold_label']\n",
    "                    sample['sentence1'] = obj['sentence1']\n",
    "                    sample['sentence2'] = obj['sentence2']\n",
    "                    self.data.append(sample)\n",
    "                else:\n",
    "                    numInvalid+=1\n",
    "        print len(self.data)\n",
    "        print numInvalid\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549367\n",
      "785\n"
     ]
    }
   ],
   "source": [
    "pp = Preprocessor()\n",
    "pp.getDataFromJSONL('./snli_1.0_train.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/seasnake/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#nltk.download(\"stopwords\")\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "stop = set(stopwords.words('english'))\n",
    "BLEU_Score_List = []\n",
    "for j in range(len(pp.data)):\n",
    "    weights = [1./4., 1./4., 1./4., 1./4.]\n",
    "    sentence1 = pp.data[j]['sentence1']\n",
    "    sentence1 = unicodedata.normalize('NFKD', sentence1).encode('ascii','ignore')\n",
    "    reference = [[i for i in sentence1.lower().split() if i not in stop]]\n",
    "    sentence2 = pp.data[j]['sentence2']\n",
    "    sentence2 = unicodedata.normalize('NFKD', sentence2).encode('ascii','ignore')\n",
    "    candidate = [i for i in sentence2.lower().split() if i not in stop]\n",
    "    length = min([len(reference[0]), len(candidate)]) \n",
    "    if length == 0:\n",
    "        BLEU_Score_List.append(0)\n",
    "    else:\n",
    "        if length < 4:\n",
    "            weights = ( 1. / length ,) * length\n",
    "        score = sentence_bleu(reference, candidate, weights)\n",
    "        BLEU_Score_List.append(score)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'BLEU_Score_List' (list) to file 'BLEU_Score_List.txt'.\n"
     ]
    }
   ],
   "source": [
    "%store BLEU_Score_List > BLEU_Score_List.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BLEU_Score_List = eval(open(\"BLEU_Score_List.txt\").read())  \n",
    "BLEU_Score_Array = np.array(BLEU_Score_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BLEU_Score_Array = BLEU_Score_Array[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Target_List = [pp.data[j]['gold_label'] for j in range(len(pp.data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'Target_List' (list) to file 'Target_List.txt'.\n"
     ]
    }
   ],
   "source": [
    "%store Target_List > Target_List.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Target_List = eval(open(\"Target_List.txt\").read())  \n",
    "Target_Array = np.array(Target_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(549367,)\n"
     ]
    }
   ],
   "source": [
    "print Target_Array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(549367, 1)\n"
     ]
    }
   ],
   "source": [
    "print BLEU_Score_Array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9824\n",
      "176\n"
     ]
    }
   ],
   "source": [
    "tt = Preprocessor()\n",
    "tt.getDataFromJSONL('./snli_1.0_test.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nltk.download(\"stopwords\")\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "stop = set(stopwords.words('english'))\n",
    "BLEU_Score_List_Test = []\n",
    "for j in range(len(tt.data)):\n",
    "    weights = [1./4., 1./4., 1./4., 1./4.]\n",
    "    sentence1 = tt.data[j]['sentence1']\n",
    "    sentence1 = unicodedata.normalize('NFKD', sentence1).encode('ascii','ignore')\n",
    "    reference = [[i for i in sentence1.lower().split() if i not in stop]]\n",
    "    sentence2 = tt.data[j]['sentence2']\n",
    "    sentence2 = unicodedata.normalize('NFKD', sentence2).encode('ascii','ignore')\n",
    "    candidate = [i for i in sentence2.lower().split() if i not in stop]\n",
    "    length = min([len(reference[0]), len(candidate)]) \n",
    "    if length == 0:\n",
    "        BLEU_Score_List_Test.append(0)\n",
    "    else:\n",
    "        if length < 4:\n",
    "            weights = ( 1. / length ,) * length\n",
    "        score = sentence_bleu(reference, candidate, weights)\n",
    "        BLEU_Score_List_Test.append(score)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'BLEU_Score_List_Test' (list) to file 'BLEU_Score_List_Test.txt'.\n"
     ]
    }
   ],
   "source": [
    "%store BLEU_Score_List_Test > BLEU_Score_List_Test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BLEU_Score_List_Test = eval(open(\"BLEU_Score_List_Test.txt\").read())  \n",
    "BLEU_Score_Array_Test = np.array(BLEU_Score_List_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BLEU_Score_Array_Test = BLEU_Score_Array_Test[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Target_List_Test = [tt.data[j]['gold_label'] for j in range(len(tt.data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'Target_List_Test' (list) to file 'Target_List_Test.txt'.\n"
     ]
    }
   ],
   "source": [
    "%store Target_List_Test > Target_List_Test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Target_List_Test = eval(open(\"Target_List_Test.txt\").read())\n",
    "Target_Array_Test = np.array(Target_List_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_list_train' (list) to file 'y_pred_list_train.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred_train = gnb.fit(BLEU_Score_Array, Target_Array).predict(BLEU_Score_Array)\n",
    "y_pred_list_train = y_pred_train.tolist()\n",
    "%store y_pred_list_train > y_pred_list_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 549367 points : 331625\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (BLEU_Score_Array.shape[0],(Target_Array != y_pred_train).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217742\n"
     ]
    }
   ],
   "source": [
    "print 549367 - 331625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.396350709089\n"
     ]
    }
   ],
   "source": [
    "print 217742./549367."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_list' (list) to file 'y_pred_list.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(BLEU_Score_Array, Target_Array).predict(BLEU_Score_Array_Test)\n",
    "y_pred_list = y_pred.tolist()\n",
    "%store y_pred_list > y_pred_list.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 9824 points : 5957\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (BLEU_Score_Array_Test.shape[0],(Target_Array_Test != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3867\n"
     ]
    }
   ],
   "source": [
    "print 9824 - 5957"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.393627850163\n"
     ]
    }
   ],
   "source": [
    "print 3867./9824."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_list_mnb' (list) to file 'y_pred_list_mnb.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "y_pred_mnb = mnb.fit(BLEU_Score_Array, Target_Array).predict(BLEU_Score_Array_Test)\n",
    "y_pred_list_mnb = y_pred_mnb.tolist()\n",
    "%store y_pred_list_mnb > y_pred_list_mnb.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 9824 points : 6456\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (BLEU_Score_Array_Test.shape[0],(Target_Array_Test != y_pred_mnb).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3368\n"
     ]
    }
   ],
   "source": [
    "print 9824 - 6456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.342833876221\n"
     ]
    }
   ],
   "source": [
    "print 3368./9824."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_list_svm_train' (list) to file 'y_pred_list_svm_train.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "y_pred_svm_train = clf.fit(BLEU_Score_Array, Target_Array).predict(BLEU_Score_Array)\n",
    "y_pred_list_svm_train = y_pred_svm_train.tolist()\n",
    "%store y_pred_list_svm_train > y_pred_list_svm_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 549367 points : 361681\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (BLEU_Score_Array.shape[0],(Target_Array != y_pred_svm_train).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187686\n"
     ]
    }
   ],
   "source": [
    "print 549367 - 361681"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34164046985\n"
     ]
    }
   ],
   "source": [
    "print 187686./549367."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_list_svm' (list) to file 'y_pred_list_svm.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "y_pred_svm = clf.fit(BLEU_Score_Array, Target_Array).predict(BLEU_Score_Array_Test)\n",
    "y_pred_list_svm = y_pred_svm.tolist()\n",
    "%store y_pred_list_svm > y_pred_list_svm.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 9824 points : 6587\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (BLEU_Score_Array_Test.shape[0],(Target_Array_Test != y_pred_svm).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3237\n"
     ]
    }
   ],
   "source": [
    "print 9824 - 6587"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.329499185668\n"
     ]
    }
   ],
   "source": [
    "print 3237./9824."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_list_lr_train' (list) to file 'y_pred_list_lr_train.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.LogisticRegression()\n",
    "y_pred_lr_train = clf.fit(BLEU_Score_Array, Target_Array).predict(BLEU_Score_Array)\n",
    "y_pred_list_lr_train = y_pred_lr_train.tolist()\n",
    "%store y_pred_list_lr_train > y_pred_list_lr_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 549367 points : 344628\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (BLEU_Score_Array.shape[0],(Target_Array != y_pred_lr_train).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204739\n"
     ]
    }
   ],
   "source": [
    "print 549367 - 344628"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.372681649972\n"
     ]
    }
   ],
   "source": [
    "print 204739./549367."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_list_lr' (list) to file 'y_pred_list_lr.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.LogisticRegression()\n",
    "y_pred_lr = clf.fit(BLEU_Score_Array, Target_Array).predict(BLEU_Score_Array_Test)\n",
    "y_pred_list_lr = y_pred_lr.tolist()\n",
    "%store y_pred_list_lr > y_pred_list_lr.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 9824 points : 6198\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (BLEU_Score_Array_Test.shape[0],(Target_Array_Test != y_pred_lr).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3626\n"
     ]
    }
   ],
   "source": [
    "print 9824 - 6198"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.369096091205\n"
     ]
    }
   ],
   "source": [
    "print 3626./9824."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.38      0.44      0.41      3237\n",
      " entailment       0.39      0.35      0.37      3368\n",
      "    neutral       0.41      0.39      0.40      3219\n",
      "\n",
      "avg / total       0.39      0.39      0.39      9824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(Target_Array_Test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.00      0.00      0.00      3237\n",
      " entailment       0.34      1.00      0.51      3368\n",
      "    neutral       0.00      0.00      0.00      3219\n",
      "\n",
      "avg / total       0.12      0.34      0.18      9824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(Target_Array_Test, y_pred_mnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.33      1.00      0.50      3237\n",
      " entailment       0.00      0.00      0.00      3368\n",
      "    neutral       0.00      0.00      0.00      3219\n",
      "\n",
      "avg / total       0.11      0.33      0.16      9824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(Target_Array_Test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.36      0.63      0.45      3237\n",
      " entailment       0.48      0.01      0.02      3368\n",
      "    neutral       0.39      0.48      0.43      3219\n",
      "\n",
      "avg / total       0.41      0.37      0.30      9824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(Target_Array_Test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1434,  919,  884],\n",
       "       [1253, 1192,  923],\n",
       "       [1062,  916, 1241]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(Target_Array_Test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2034,   22, 1181],\n",
       "       [2044,   39, 1285],\n",
       "       [1645,   21, 1553]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(Target_Array_Test, y_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Length_Difference_List = []\n",
    "for j in range(len(pp.data)):\n",
    "    sentence1 = pp.data[j]['sentence1']\n",
    "    sentence1 = unicodedata.normalize('NFKD', sentence1).encode('ascii','ignore')\n",
    "    premise = [i for i in sentence1.lower().split()]\n",
    "    sentence2 = pp.data[j]['sentence2']\n",
    "    sentence2 = unicodedata.normalize('NFKD', sentence2).encode('ascii','ignore')\n",
    "    hypothesis = [i for i in sentence2.lower().split()]\n",
    "    length_diff = len(premise)-len(hypothesis)\n",
    "    Length_Difference_List.append(length_diff)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'Length_Difference_List' (list) to file 'Length_Difference_List.txt'.\n"
     ]
    }
   ],
   "source": [
    "%store Length_Difference_List > Length_Difference_List.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Length_Difference_List = eval(open(\"Length_Difference_List.txt\").read())  \n",
    "Length_Difference_Array = np.array(Length_Difference_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Length_Difference_Array = Length_Difference_Array[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Two_Features = np.concatenate((BLEU_Score_Array, Length_Difference_Array), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(549367, 2)\n"
     ]
    }
   ],
   "source": [
    "print Two_Features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Length_Difference_List_Test = []\n",
    "for j in range(len(tt.data)):\n",
    "    sentence1 = tt.data[j]['sentence1']\n",
    "    sentence1 = unicodedata.normalize('NFKD', sentence1).encode('ascii','ignore')\n",
    "    premise = [i for i in sentence1.lower().split()]\n",
    "    sentence2 = tt.data[j]['sentence2']\n",
    "    sentence2 = unicodedata.normalize('NFKD', sentence2).encode('ascii','ignore')\n",
    "    hypothesis = [i for i in sentence2.lower().split()]\n",
    "    length_diff = len(premise)-len(hypothesis)\n",
    "    Length_Difference_List_Test.append(length_diff)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'Length_Difference_List_Test' (list) to file 'Length_Difference_List_Test.txt'.\n"
     ]
    }
   ],
   "source": [
    "%store Length_Difference_List_Test > Length_Difference_List_Test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Length_Difference_List_Test = eval(open(\"Length_Difference_List_Test.txt\").read())\n",
    "Length_Difference_Array_Test = np.array(Length_Difference_List_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Length_Difference_Array_Test = Length_Difference_Array_Test[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Two_Features_Test = np.concatenate((BLEU_Score_Array_Test, Length_Difference_Array_Test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9824, 2)\n"
     ]
    }
   ],
   "source": [
    "print Two_Features_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_2_list_train' (list) to file 'y_pred_2_list_train.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred_2_train = gnb.fit(Two_Features, Target_Array).predict(Two_Features)\n",
    "y_pred_2_list_train = y_pred_2_train.tolist()\n",
    "%store y_pred_2_list_train > y_pred_2_list_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 549367 points : 329733\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (Two_Features.shape[0],(Target_Array != y_pred_2_train).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219634\n"
     ]
    }
   ],
   "source": [
    "print 549367 - 329733"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.399794672778\n"
     ]
    }
   ],
   "source": [
    "print 219634./549367."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_2_list' (list) to file 'y_pred_2_list.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred_2 = gnb.fit(Two_Features, Target_Array).predict(Two_Features_Test)\n",
    "y_pred_2_list = y_pred_2.tolist()\n",
    "%store y_pred_2_list > y_pred_2_list.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 9824 points : 5897\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (Two_Features_Test.shape[0],(Target_Array_Test != y_pred_2).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3927\n"
     ]
    }
   ],
   "source": [
    "print 9824 - 5897"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39973534202\n"
     ]
    }
   ],
   "source": [
    "print 3927./9824."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.42      0.21      0.28      3237\n",
      " entailment       0.39      0.59      0.47      3368\n",
      "    neutral       0.40      0.40      0.40      3219\n",
      "\n",
      "avg / total       0.41      0.40      0.38      9824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(Target_Array_Test, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 677, 1624,  936],\n",
       "       [ 434, 1977,  957],\n",
       "       [ 490, 1456, 1273]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(Target_Array_Test, y_pred_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_list_svm_2_train' (list) to file 'y_pred_list_svm_2_train.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "y_pred_2_svm_train = clf.fit(Two_Features, Target_Array).predict(Two_Features)\n",
    "y_pred_list_svm_2_train = y_pred_2_svm_train.tolist()\n",
    "%store y_pred_list_svm_2_train > y_pred_list_svm_2_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 549367 points : 336877\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (Two_Features.shape[0],(Target_Array != y_pred_2_svm_train).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212490\n"
     ]
    }
   ],
   "source": [
    "print 549367 - 336877"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.386790615381\n"
     ]
    }
   ],
   "source": [
    "print 212490./549367."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_list_svm_2' (list) to file 'y_pred_list_svm_2.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "y_pred_2_svm = clf.fit(Two_Features, Target_Array).predict(Two_Features_Test)\n",
    "y_pred_list_svm_2 = y_pred_2_svm.tolist()\n",
    "%store y_pred_list_svm_2 > y_pred_list_svm_2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 9824 points : 6005\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (Two_Features_Test.shape[0],(Target_Array_Test != y_pred_2_svm).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3819\n"
     ]
    }
   ],
   "source": [
    "print 9824 - 6005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.388741856678\n"
     ]
    }
   ],
   "source": [
    "print 3819./9824."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.44      0.04      0.08      3237\n",
      " entailment       0.37      0.89      0.52      3368\n",
      "    neutral       0.49      0.21      0.29      3219\n",
      "\n",
      "avg / total       0.43      0.39      0.30      9824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(Target_Array_Test, y_pred_2_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 136, 2688,  413],\n",
       "       [  71, 3013,  284],\n",
       "       [ 105, 2444,  670]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(Target_Array_Test, y_pred_2_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_list_lr_2_train' (list) to file 'y_pred_list_lr_2_train.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.LogisticRegression()\n",
    "y_pred_2_lr_train = clf.fit(Two_Features, Target_Array).predict(Two_Features)\n",
    "y_pred_list_lr_2_train = y_pred_2_lr_train.tolist()\n",
    "%store y_pred_list_lr_2_train > y_pred_list_lr_2_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 549367 points : 337283\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (Two_Features.shape[0],(Target_Array != y_pred_2_lr_train).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212084\n"
     ]
    }
   ],
   "source": [
    "print 549367 - 337283"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.386051583004\n"
     ]
    }
   ],
   "source": [
    "print 212084./549367."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_list_lr_2' (list) to file 'y_pred_list_lr_2.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.LogisticRegression()\n",
    "y_pred_2_lr = clf.fit(Two_Features, Target_Array).predict(Two_Features_Test)\n",
    "y_pred_list_lr_2 = y_pred_2_lr.tolist()\n",
    "%store y_pred_list_lr_2 > y_pred_list_lr_2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 9824 points : 6029\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (Two_Features_Test.shape[0],(Target_Array_Test != y_pred_2_lr).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3795\n"
     ]
    }
   ],
   "source": [
    "print 9824 - 6029"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.386298859935\n"
     ]
    }
   ],
   "source": [
    "print 3795./9824."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.38      0.33      0.36      3237\n",
      " entailment       0.39      0.40      0.39      3368\n",
      "    neutral       0.39      0.43      0.41      3219\n",
      "\n",
      "avg / total       0.39      0.39      0.39      9824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(Target_Array_Test, y_pred_2_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nltk.download(\"stopwords\")\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "stop = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "Overlap_Percent = []\n",
    "for j in range(len(pp.data)):\n",
    "    sentence1 = pp.data[j]['sentence1']\n",
    "    sentence1 = unicodedata.normalize('NFKD', sentence1).encode('ascii','ignore')\n",
    "    premise = [ps.stem(i) for i in sentence1.lower().split() if i not in stop]\n",
    "    sentence2 = pp.data[j]['sentence2']\n",
    "    sentence2 = unicodedata.normalize('NFKD', sentence2).encode('ascii','ignore')\n",
    "    hypothesis = [ps.stem(i) for i in sentence2.lower().split() if i not in stop]\n",
    "    lengtharray = np.array([len(premise), len(hypothesis)])\n",
    "    length = np.min(lengtharray)\n",
    "    indx = np.argmin(lengtharray)\n",
    "    if length == 0:\n",
    "        Overlap_Percent.append(0)\n",
    "    else:\n",
    "        count = 0\n",
    "        if indx == 0:\n",
    "            for j in range(length):\n",
    "                if premise[j] in hypothesis:\n",
    "                    count = count+1\n",
    "        else:\n",
    "            for j in range(length):\n",
    "                if hypothesis[j] in premise:\n",
    "                    count = count+1\n",
    "        Overlap_Percent.append(count/float(length))                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'Overlap_Percent' (list) to file 'Overlap_Percent.txt'.\n"
     ]
    }
   ],
   "source": [
    "%store Overlap_Percent > Overlap_Percent.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Overlap_Percent = eval(open(\"Overlap_Percent.txt\").read())\n",
    "Overlap_Percent_Array = np.array(Overlap_Percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Overlap_Percent_Array = Overlap_Percent_Array[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#nltk.download(\"stopwords\")\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "stop = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "Overlap_Percent_Test = []\n",
    "for j in range(len(tt.data)):\n",
    "    sentence1 = tt.data[j]['sentence1']\n",
    "    sentence1 = unicodedata.normalize('NFKD', sentence1).encode('ascii','ignore')\n",
    "    premise = [ps.stem(i) for i in sentence1.lower().split() if i not in stop]\n",
    "    sentence2 = tt.data[j]['sentence2']\n",
    "    sentence2 = unicodedata.normalize('NFKD', sentence2).encode('ascii','ignore')\n",
    "    hypothesis = [ps.stem(i) for i in sentence2.lower().split() if i not in stop]\n",
    "    lengtharray = np.array([len(premise), len(hypothesis)])\n",
    "    length = np.min(lengtharray)\n",
    "    indx = np.argmin(lengtharray)\n",
    "    if length == 0:\n",
    "        Overlap_Percent_Test.append(0)\n",
    "    else:\n",
    "        count = 0\n",
    "        if indx == 0:\n",
    "            for j in range(length):\n",
    "                if premise[j] in hypothesis:\n",
    "                    count = count+1\n",
    "        else:\n",
    "            for j in range(length):\n",
    "                if hypothesis[j] in premise:\n",
    "                    count = count+1\n",
    "        Overlap_Percent_Test.append(count/float(length))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'Overlap_Percent_Test' (list) to file 'Overlap_Percent_Test.txt'.\n"
     ]
    }
   ],
   "source": [
    "%store Overlap_Percent_Test > Overlap_Percent_Test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Overlap_Percent_Test = eval(open(\"Overlap_Percent_Test.txt\").read())\n",
    "Overlap_Percent_Array_Test = np.array(Overlap_Percent_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Overlap_Percent_Array_Test = Overlap_Percent_Array_Test[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Three_Features = np.concatenate((Two_Features, Overlap_Percent_Array), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(549367, 3)\n"
     ]
    }
   ],
   "source": [
    "print Three_Features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Three_Features_Test = np.concatenate((Two_Features_Test, Overlap_Percent_Array_Test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9824, 3)\n"
     ]
    }
   ],
   "source": [
    "print Three_Features_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_3_list_train' (list) to file 'y_pred_3_list_train.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred_3_train = gnb.fit(Three_Features, Target_Array).predict(Three_Features)\n",
    "y_pred_3_list_train = y_pred_3_train.tolist()\n",
    "%store y_pred_3_list_train > y_pred_3_list_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 549367 points : 293646\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (Three_Features.shape[0],(Target_Array != y_pred_3_train).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255721\n"
     ]
    }
   ],
   "source": [
    "print 549367-293646"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.465483001345\n"
     ]
    }
   ],
   "source": [
    "print 255721./549367."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_3_list' (list) to file 'y_pred_3_list.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred_3 = gnb.fit(Three_Features, Target_Array).predict(Three_Features_Test)\n",
    "y_pred_3_list = y_pred_3.tolist()\n",
    "%store y_pred_3_list > y_pred_3_list.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 9824 points : 5174\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (Three_Features_Test.shape[0],(Target_Array_Test != y_pred_3).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4650\n"
     ]
    }
   ],
   "source": [
    "print 9824 - 5174"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.473330618893\n"
     ]
    }
   ],
   "source": [
    "print 4650./9824."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.43      0.54      0.48      3237\n",
      " entailment       0.55      0.54      0.55      3368\n",
      "    neutral       0.43      0.34      0.38      3219\n",
      "\n",
      "avg / total       0.47      0.47      0.47      9824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(Target_Array_Test, y_pred_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1735,  680,  822],\n",
       "       [ 937, 1823,  608],\n",
       "       [1340,  787, 1092]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(Target_Array_Test, y_pred_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_list_svm_3_train' (list) to file 'y_pred_list_svm_3_train.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "y_pred_3_svm_train = clf.fit(Three_Features, Target_Array).predict(Three_Features)\n",
    "y_pred_list_svm_3_train = y_pred_3_svm_train.tolist()\n",
    "%store y_pred_list_svm_3_train > y_pred_list_svm_3_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 549367 points : 314507\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (Three_Features.shape[0],(Target_Array != y_pred_3_svm_train).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234860\n"
     ]
    }
   ],
   "source": [
    "print 549367 - 314507"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.427510207202\n"
     ]
    }
   ],
   "source": [
    "print 234860./549367."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_list_svm_3' (list) to file 'y_pred_list_svm_3.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "y_pred_3_svm = clf.fit(Three_Features, Target_Array).predict(Three_Features_Test)\n",
    "y_pred_list_svm_3 = y_pred_3_svm.tolist()\n",
    "%store y_pred_list_svm_3 > y_pred_list_svm_3.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 9824 points : 5304\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (Three_Features_Test.shape[0],(Target_Array_Test != y_pred_3_svm).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4520\n"
     ]
    }
   ],
   "source": [
    "print 9824 - 5304"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46009771987\n"
     ]
    }
   ],
   "source": [
    "print 4520./9824."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.42      0.63      0.51      3237\n",
      " entailment       0.49      0.64      0.56      3368\n",
      "    neutral       0.49      0.10      0.17      3219\n",
      "\n",
      "avg / total       0.47      0.46      0.41      9824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(Target_Array_Test, y_pred_3_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2030,  995,  212],\n",
       "       [1083, 2167,  118],\n",
       "       [1667, 1229,  323]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(Target_Array_Test, y_pred_3_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_list_lr_3_train' (list) to file 'y_pred_list_lr_3_train.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.LogisticRegression()\n",
    "y_pred_3_lr_train = clf.fit(Three_Features, Target_Array).predict(Three_Features)\n",
    "y_pred_list_lr_3_train = y_pred_3_lr_train.tolist()\n",
    "%store y_pred_list_lr_3_train > y_pred_list_lr_3_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 549367 points : 297395\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (Three_Features.shape[0],(Target_Array != y_pred_3_lr_train).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251972\n"
     ]
    }
   ],
   "source": [
    "print 549367 - 297395"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.458658783655\n"
     ]
    }
   ],
   "source": [
    "print 251972./549367."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_list_lr_3' (list) to file 'y_pred_list_lr_3.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.LogisticRegression()\n",
    "y_pred_3_lr = clf.fit(Three_Features, Target_Array).predict(Three_Features_Test)\n",
    "y_pred_list_lr_3 = y_pred_3_lr.tolist()\n",
    "%store y_pred_list_lr_3 > y_pred_list_lr_3.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 9824 points : 5253\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (Three_Features_Test.shape[0],(Target_Array_Test != y_pred_3_lr).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4571\n"
     ]
    }
   ],
   "source": [
    "print 9824 - 5253"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.465289087948\n"
     ]
    }
   ],
   "source": [
    "print 4571./9824."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.45      0.48      0.46      3237\n",
      " entailment       0.50      0.62      0.56      3368\n",
      "    neutral       0.42      0.29      0.34      3219\n",
      "\n",
      "avg / total       0.46      0.47      0.46      9824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(Target_Array_Test, y_pred_3_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.45      0.48      0.46      3237\n",
      " entailment       0.50      0.62      0.56      3368\n",
      "    neutral       0.42      0.29      0.34      3219\n",
      "\n",
      "avg / total       0.46      0.47      0.46      9824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(Target_Array_Test, y_pred_3_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "#nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence1 = pp.data[2]['sentence1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ss = sid.polarity_scores(sentence1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.307, 'neu': 0.693, 'pos': 0.0, 'compound': -0.4767}\n"
     ]
    }
   ],
   "source": [
    "print ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A person on a horse jumps over a broken down airplane.\n"
     ]
    }
   ],
   "source": [
    "print sentence1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence2 = pp.data[2]['sentence2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ss = sid.polarity_scores(sentence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n"
     ]
    }
   ],
   "source": [
    "print ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A person is outdoors, on a horse.\n"
     ]
    }
   ],
   "source": [
    "print sentence2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({u' ': 6, u'o': 6, u's': 4, u'r': 3, u'e': 2, u'n': 2, u'A': 1, u'd': 1, u'i': 1, u'h': 1, u',': 1, u'p': 1, u'u': 1, u't': 1, u'a': 1, u'.': 1})\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'Premise_Sentiment' (list) to file 'Premise_Sentiment.txt'.\n",
      "Writing 'Hypothesis_Sentiment' (list) to file 'Hypothesis_Sentiment.txt'.\n",
      "Writing 'Match' (list) to file 'Match.txt'.\n"
     ]
    }
   ],
   "source": [
    "Premise_Sentiment = []\n",
    "Hypothesis_Sentiment = []\n",
    "Match = []\n",
    "for j in range(len(pp.data)):\n",
    "    sentence1 = pp.data[j]['sentence1']\n",
    "    premise_ss = sid.polarity_scores(sentence1)\n",
    "    Premise_Sentiment.append(premise_ss['compound'])\n",
    "    sentence2 = pp.data[j]['sentence2']\n",
    "    hypothesis_ss = sid.polarity_scores(sentence2)\n",
    "    Hypothesis_Sentiment.append(hypothesis_ss['compound'])\n",
    "    if premise_ss['compound'] >= 0 and hypothesis_ss['compound'] >= 0:\n",
    "        Match.append(1)\n",
    "    elif premise_ss['compound'] >=0 and hypothesis_ss['compound'] < 0:\n",
    "        Match.append(-1)\n",
    "    elif premise_ss['compound'] < 0 and hypothesis_ss['compound'] >= 0:\n",
    "        Match.append(-1)\n",
    "    else:\n",
    "        Match.append(1)\n",
    "%store Premise_Sentiment > Premise_Sentiment.txt\n",
    "%store Hypothesis_Sentiment > Hypothesis_Sentiment.txt\n",
    "%store Match > Match.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Premise_Sentiment = eval(open(\"Premise_Sentiment.txt\").read())\n",
    "Premise_Sentiment_Array = np.array(Premise_Sentiment)\n",
    "Hypothesis_Sentiment = eval(open(\"Hypothesis_Sentiment.txt\").read())\n",
    "Hypothesis_Sentiment_Array = np.array(Hypothesis_Sentiment)\n",
    "Match = eval(open(\"Match.txt\").read())\n",
    "Match_Array = np.array(Match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Premise_Sentiment_Array = Premise_Sentiment_Array[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Hypothesis_Sentiment_Array = Hypothesis_Sentiment_Array[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Match_Array = Match_Array[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Six_Features = np.concatenate((Three_Features, Premise_Sentiment_Array, Hypothesis_Sentiment_Array, Match_Array), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(549367, 6)\n"
     ]
    }
   ],
   "source": [
    "print Six_Features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'Premise_Sentiment_Test' (list) to file 'Premise_Sentiment_Test.txt'.\n",
      "Writing 'Hypothesis_Sentiment_Test' (list) to file 'Hypothesis_Sentiment_Test.txt'.\n",
      "Writing 'Match_Test' (list) to file 'Match_Test.txt'.\n"
     ]
    }
   ],
   "source": [
    "Premise_Sentiment_Test = []\n",
    "Hypothesis_Sentiment_Test = []\n",
    "Match_Test = []\n",
    "for j in range(len(tt.data)):\n",
    "    sentence1 = tt.data[j]['sentence1']\n",
    "    premise_ss = sid.polarity_scores(sentence1)\n",
    "    Premise_Sentiment_Test.append(premise_ss['compound'])\n",
    "    sentence2 = tt.data[j]['sentence2']\n",
    "    hypothesis_ss = sid.polarity_scores(sentence2)\n",
    "    Hypothesis_Sentiment_Test.append(hypothesis_ss['compound'])\n",
    "    if premise_ss['compound'] >= 0 and hypothesis_ss['compound'] >= 0:\n",
    "        Match_Test.append(1)\n",
    "    elif premise_ss['compound'] >=0 and hypothesis_ss['compound'] < 0:\n",
    "        Match_Test.append(-1)\n",
    "    elif premise_ss['compound'] < 0 and hypothesis_ss['compound'] >= 0:\n",
    "        Match_Test.append(-1)\n",
    "    else:\n",
    "        Match_Test.append(1)\n",
    "%store Premise_Sentiment_Test > Premise_Sentiment_Test.txt\n",
    "%store Hypothesis_Sentiment_Test > Hypothesis_Sentiment_Test.txt\n",
    "%store Match_Test > Match_Test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Premise_Sentiment_Test = eval(open(\"Premise_Sentiment_Test.txt\").read())\n",
    "Premise_Sentiment_Array_Test = np.array(Premise_Sentiment_Test)\n",
    "Hypothesis_Sentiment_Test = eval(open(\"Hypothesis_Sentiment_Test.txt\").read())\n",
    "Hypothesis_Sentiment_Array_Test = np.array(Hypothesis_Sentiment_Test)\n",
    "Match_Test = eval(open(\"Match_Test.txt\").read())\n",
    "Match_Array_Test = np.array(Match_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Premise_Sentiment_Array_Test = Premise_Sentiment_Array_Test[:, np.newaxis]\n",
    "Hypothesis_Sentiment_Array_Test = Hypothesis_Sentiment_Array_Test[:, np.newaxis]\n",
    "Match_Array_Test = Match_Array_Test[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Six_Features_Test = np.concatenate((Three_Features_Test, Premise_Sentiment_Array_Test, Hypothesis_Sentiment_Array_Test, Match_Array_Test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9824, 6)\n"
     ]
    }
   ],
   "source": [
    "print Six_Features_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_6_list' (list) to file 'y_pred_6_list.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred_6 = gnb.fit(Six_Features, Target_Array).predict(Six_Features_Test)\n",
    "y_pred_6_list = y_pred_6.tolist()\n",
    "%store y_pred_6_list > y_pred_6_list.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 9824 points : 5309\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (Six_Features_Test.shape[0],(Target_Array_Test != y_pred_6).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_list_svm_6' (list) to file 'y_pred_list_svm_6.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "y_pred_6_svm = clf.fit(Six_Features, Target_Array).predict(Six_Features_Test)\n",
    "y_pred_list_svm_6 = y_pred_6_svm.tolist()\n",
    "%store y_pred_list_svm_6 > y_pred_list_svm_6.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 9824 points : 5115\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (Six_Features_Test.shape[0],(Target_Array_Test != y_pred_6_svm).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_list_lr_6' (list) to file 'y_pred_list_lr_6.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.LogisticRegression()\n",
    "y_pred_6_lr = clf.fit(Six_Features, Target_Array).predict(Six_Features_Test)\n",
    "y_pred_list_lr_6 = y_pred_6_lr.tolist()\n",
    "%store y_pred_list_lr_6 > y_pred_list_lr_6.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 9824 points : 5092\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (Six_Features_Test.shape[0],(Target_Array_Test != y_pred_6_lr).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4732\n"
     ]
    }
   ],
   "source": [
    "print 9824 - 5092"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48167752443\n"
     ]
    }
   ],
   "source": [
    "print 4732./9824."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Five_Features = np.concatenate((Three_Features, Hypothesis_Sentiment_Array, Match_Array), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Five_Features_Test = np.concatenate((Three_Features_Test, Hypothesis_Sentiment_Array_Test, Match_Array_Test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_5_list' (list) to file 'y_pred_5_list.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred_5 = gnb.fit(Five_Features, Target_Array).predict(Five_Features_Test)\n",
    "y_pred_5_list = y_pred_5.tolist()\n",
    "%store y_pred_5_list > y_pred_5_list.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 9824 points : 5310\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (Five_Features_Test.shape[0],(Target_Array_Test != y_pred_5).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_list_svm_5' (list) to file 'y_pred_list_svm_5.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "y_pred_5_svm = clf.fit(Five_Features, Target_Array).predict(Five_Features_Test)\n",
    "y_pred_list_svm_5 = y_pred_5_svm.tolist()\n",
    "%store y_pred_list_svm_5 > y_pred_list_svm_5.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 9824 points : 5284\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (Five_Features_Test.shape[0],(Target_Array_Test != y_pred_5_svm).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_list_lr_5' (list) to file 'y_pred_list_lr_5.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.LogisticRegression()\n",
    "y_pred_5_lr = clf.fit(Five_Features, Target_Array).predict(Five_Features_Test)\n",
    "y_pred_list_lr_5 = y_pred_5_lr.tolist()\n",
    "%store y_pred_list_lr_5 > y_pred_list_lr_5.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 9824 points : 5078\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (Five_Features_Test.shape[0],(Target_Array_Test != y_pred_5_lr).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Four_Features_H = np.concatenate((Three_Features, Hypothesis_Sentiment_Array), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Four_Features_Test_H = np.concatenate((Three_Features_Test, Hypothesis_Sentiment_Array_Test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_4_list_h' (list) to file 'y_pred_4_list_h.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred_4_h = gnb.fit(Four_Features_H, Target_Array).predict(Four_Features_Test_H)\n",
    "y_pred_4_list_h = y_pred_4_h.tolist()\n",
    "%store y_pred_4_list_h > y_pred_4_list_h.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 9824 points : 5025\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (Four_Features_Test_H.shape[0],(Target_Array_Test != y_pred_4_h).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4799\n"
     ]
    }
   ],
   "source": [
    "print 9824 - 5025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.488497557003\n"
     ]
    }
   ],
   "source": [
    "print 4799./9824."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_list_svm_4_h' (list) to file 'y_pred_list_svm_4_h.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "y_pred_4_svm_h = clf.fit(Four_Features_H, Target_Array).predict(Four_Features_Test_H)\n",
    "y_pred_list_svm_4_h = y_pred_4_svm_h.tolist()\n",
    "%store y_pred_list_svm_4_h > y_pred_list_svm_4_h.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 9824 points : 5373\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (Four_Features_Test_H.shape[0],(Target_Array_Test != y_pred_4_svm_h).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_list_lr_4_h' (list) to file 'y_pred_list_lr_4_h.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.LogisticRegression()\n",
    "y_pred_4_lr_h = clf.fit(Four_Features_H, Target_Array).predict(Four_Features_Test_H)\n",
    "y_pred_list_lr_4_h = y_pred_4_lr_h.tolist()\n",
    "%store y_pred_list_lr_4_h > y_pred_list_lr_4_h.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 9824 points : 5085\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (Four_Features_Test_H.shape[0],(Target_Array_Test != y_pred_4_lr_h).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Four_Features_M = np.concatenate((Three_Features, Match_Array), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Four_Features_Test_M = np.concatenate((Three_Features_Test, Match_Array_Test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_4_list_m' (list) to file 'y_pred_4_list_m.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred_4_m = gnb.fit(Four_Features_H, Target_Array).predict(Four_Features_Test_H)\n",
    "y_pred_4_list_m = y_pred_4_m.tolist()\n",
    "%store y_pred_4_list_m > y_pred_4_list_m.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 9824 points : 5025\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (Four_Features_Test_M.shape[0],(Target_Array_Test != y_pred_4_m).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_list_svm_4_m' (list) to file 'y_pred_list_svm_4_m.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "y_pred_4_svm_m = clf.fit(Four_Features_M, Target_Array).predict(Four_Features_Test_M)\n",
    "y_pred_list_svm_4_m = y_pred_4_svm_m.tolist()\n",
    "%store y_pred_list_svm_4_m > y_pred_list_svm_4_m.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 9824 points : 5358\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (Four_Features_Test_M.shape[0],(Target_Array_Test != y_pred_4_svm_m).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_list_lr_4_m' (list) to file 'y_pred_list_lr_4_m.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.LogisticRegression()\n",
    "y_pred_4_lr_m = clf.fit(Four_Features_M, Target_Array).predict(Four_Features_Test_M)\n",
    "y_pred_list_lr_4_m = y_pred_4_lr_m.tolist()\n",
    "%store y_pred_list_lr_4_m > y_pred_list_lr_4_m.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 9824 points : 5232\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (Four_Features_Test_H.shape[0],(Target_Array_Test != y_pred_4_lr_m).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nltk.download(\"stopwords\")\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "wordCount = defaultdict(int)\n",
    "for j in range(len(pp.data)):\n",
    "    sentence2 = pp.data[j]['sentence2']\n",
    "    sentence2 = unicodedata.normalize('NFKD', sentence2).encode('ascii','ignore')\n",
    "    hypothesis = [ps.stem(i) for i in sentence2.lower().split() if i not in stop]\n",
    "    for w in hypothesis:\n",
    "        wordCount[w]+=1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'wordCount' (defaultdict) to file 'wordCount.txt'.\n"
     ]
    }
   ],
   "source": [
    "%store wordCount > wordCount.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'man', u'peopl', u'woman', u'two', u'play', u'girl', u'boy', u'dog', u'men', u'sit', u'wear', u'person', u'walk', u'stand', u'group', u'women', u'young', u'child', u'outside.', u'ride', u'look', u'hold', u'run', u'three', u'children', u'watch', u'kid', u'outsid', u'eat', u'take', u'get', u'work', u'black', u'near', u'wait', u'jump', u'player', u'white', u'ladi', u'front', u'coupl', u'red', u'one', u'go', u'blue', u'guy', u'dress', u'perform', u'littl', u'shirt', u'sleep', u'street.', u'make', u'bike', u'old', u'street', u'talk', u'tri', u'water.', u'worker', u'swim', u'outdoors.', u'beach.', u'next', u'someon', u'car', u'crowd', u'water', u'pictur', u'insid', u'use', u'around', u'park.', u'danc', u'enjoy', u'friend', u'human', u'drink', u'babi', u'larg', u'read', u'four', u'ball', u'small', u'game', u'build', u'park', u'carri', u'cat', u'soccer', u'game.', u'green', u'race', u'together.', u'drive', u'pose', u'climb', u'anim', u'famili', u'prepar']\n"
     ]
    }
   ],
   "source": [
    "# Limit the vocabulary\n",
    "wordCount = eval(open(\"wordCount.txt\").read())\n",
    "uni_sorted = sorted(wordCount.items(), key=operator.itemgetter(1)) [::-1]\n",
    "vocab = [item[0] for item in uni_sorted[:10000]]\n",
    "print vocab[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#nltk.download(\"stopwords\")\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "Char_Vector_List = []\n",
    "for j in range(len(pp.data)):\n",
    "    sentence2 = pp.data[j]['sentence2']\n",
    "    sentence2 = unicodedata.normalize('NFKD', sentence2).encode('ascii','ignore')\n",
    "    hypothesis = [ps.stem(i) for i in sentence2.lower().split() if i not in stop]\n",
    "    L = []\n",
    "    for w in hypothesis:\n",
    "        if w in vocab:\n",
    "            index = vocab.index(w)\n",
    "            L.append(index)\n",
    "    Char_Vector_List.append(L)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'Char_Vector_List' (list) to file 'Char_Vector_List.txt'.\n"
     ]
    }
   ],
   "source": [
    "%store Char_Vector_List > Char_Vector_List.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 148, 108, 306]\n"
     ]
    }
   ],
   "source": [
    "print Char_Vector_List[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549367\n"
     ]
    }
   ],
   "source": [
    "print len(Char_Vector_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "Char_Vector_List = eval(open(\"Char_Vector_List.txt\").read())\n",
    "indptr = [0]\n",
    "length = 0\n",
    "indices = []\n",
    "for d in Char_Vector_List:\n",
    "    length = length + len(d)\n",
    "    indptr.append(length)\n",
    "    for j in range(len(d)):\n",
    "        indices.append(d[j])\n",
    "data = np.ones(length)        \n",
    "X = csr_matrix((data, indices, indptr), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(549367, 10000)\n"
     ]
    }
   ],
   "source": [
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Three_Features_Sparse = csr_matrix(Three_Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "Many_Features = hstack([Three_Features_Sparse,X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(549367, 10003)\n"
     ]
    }
   ],
   "source": [
    "print Many_Features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#nltk.download(\"stopwords\")\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "ps = PorterStemmer()\n",
    "Char_Vector_Array_Test = np.zeros((len(tt.data),len(vocab)))\n",
    "for j in range(len(tt.data)):\n",
    "    sentence2 = tt.data[j]['sentence2']\n",
    "    sentence2 = unicodedata.normalize('NFKD', sentence2).encode('ascii','ignore')\n",
    "    hypothesis = [ps.stem(i) for i in sentence2.lower().split() if i not in stop]\n",
    "    L = []\n",
    "    for w in hypothesis:\n",
    "        if w in vocab:\n",
    "            index = vocab.index(w)\n",
    "            Char_Vector_Array_Test[j,index] = 1       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9824, 10000)\n"
     ]
    }
   ],
   "source": [
    "print Char_Vector_Array_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Many_Features_Test = np.concatenate((Three_Features_Test, Char_Vector_Array_Test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9824, 10003)\n"
     ]
    }
   ],
   "source": [
    "print Many_Features_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_list_many_lr_train' (list) to file 'y_pred_list_many_lr_train.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.LogisticRegression()\n",
    "y_pred_many_lr_train = clf.fit(Many_Features, Target_Array).predict(Many_Features)\n",
    "y_pred_list_many_lr_train = y_pred_many_lr_train.tolist()\n",
    "%store y_pred_list_many_lr_train > y_pred_list_many_lr_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 549367 points : 184547\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (Many_Features.shape[0],(Target_Array != y_pred_many_lr_train).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364820\n"
     ]
    }
   ],
   "source": [
    "print 549367 - 184547"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.664073378998\n"
     ]
    }
   ],
   "source": [
    "print 364820./549367."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_list_many_lr' (list) to file 'y_pred_list_many_lr.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.LogisticRegression()\n",
    "y_pred_many_lr = clf.fit(Many_Features, Target_Array).predict(Many_Features_Test)\n",
    "y_pred_list_many_lr = y_pred_many_lr.tolist()\n",
    "%store y_pred_list_many_lr > y_pred_list_many_lr.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 9824 points : 3301\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (Many_Features_Test.shape[0],(Target_Array_Test != y_pred_many_lr).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6523\n"
     ]
    }
   ],
   "source": [
    "print 9824 - 3301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.663986156352\n"
     ]
    }
   ],
   "source": [
    "print 6523./9824"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "contradiction       0.65      0.67      0.66      3237\n",
      " entailment       0.67      0.74      0.70      3368\n",
      "    neutral       0.67      0.58      0.62      3219\n",
      "\n",
      "avg / total       0.66      0.66      0.66      9824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(Target_Array_Test, y_pred_many_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2166,  573,  498],\n",
       "       [ 464, 2479,  425],\n",
       "       [ 684,  657, 1878]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(Target_Array_Test, y_pred_many_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_list_many_svm_train' (list) to file 'y_pred_list_many_svm_train.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "y_pred_many_svm_train = clf.fit(Many_Features, Target_Array).predict(Many_Features)\n",
    "y_pred_list_many_svm_train = y_pred_many_svm_train.tolist()\n",
    "%store y_pred_list_many_svm_train > y_pred_list_many_svm_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 549367 points : 203710\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (Many_Features.shape[0],(Target_Array != y_pred_many_svm_train).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345657\n"
     ]
    }
   ],
   "source": [
    "print 549367 - 203710"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.629191414847\n"
     ]
    }
   ],
   "source": [
    "print 345657./549367."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'y_pred_list_many_svm' (list) to file 'y_pred_list_many_svm.txt'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.SGDClassifier()\n",
    "y_pred_many_svm = clf.fit(Many_Features, Target_Array).predict(Many_Features_Test)\n",
    "y_pred_list_many_svm = y_pred_many_svm.tolist()\n",
    "%store y_pred_list_many_svm > y_pred_list_many_svm.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 9824 points : 3838\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (Many_Features_Test.shape[0],(Target_Array_Test != y_pred_many_svm).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5986\n"
     ]
    }
   ],
   "source": [
    "print 9824 - 3838"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.609324104235\n"
     ]
    }
   ],
   "source": [
    "print 5986./9824."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
